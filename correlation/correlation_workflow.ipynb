{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b8abcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_rms (generic function with 3 methods)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SeisNoise, PyPlot, CUDA, Glob, HDF5, Combinatorics, Random, Statistics, ImageFiltering, FFTW, JLD2, Dates\n",
    "import SeisNoise: NoiseData\n",
    "import SeisIO: read_nodal, NodalData, InstrumentPosition, InstrumentResponse, show_str, show_t, show_x, show_os\n",
    "import FFTW: rfft, irfft\n",
    "import Base:show, size, summary\n",
    "include(\"correlation_codes/Types.jl\")\n",
    "include(\"correlation_codes/Nodal.jl\")\n",
    "include(\"correlation_codes/Misc.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f61142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE CURRENT SPLIT POINT IS PROBABLY WRONG- USE 331 AS FIRST AND 2391 AS LAST\n",
    "\n",
    "# LOWER THE LOW FK BOUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c2e7d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workflow (generic function with 2 methods)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function workflow(files,cc_len,maxlag,freqmin,freqmax,fs,cmin,cmax,sgn,time_norm,\n",
    "                  chans,output_times,out_path,samples_per_file=[])\n",
    "    \n",
    "# baseline: resample > fk > detrend/taper/filter > whiten > 1bit > slice > correlate\n",
    "# optimized: preprocess > rfft > fk > irfft (space) > whiten > correlate\n",
    "# the preprocess function does resample/detrend/taper/filter/1bit/slice\n",
    "# compromise: \n",
    "    \n",
    "    # read the first file and collect metadata\n",
    "    N = read_nodal(\"segy\", files[1])\n",
    "    datetime = get_datetime(N)\n",
    "    if isempty(samples_per_file) == true\n",
    "        samples_per_file = N.info[\"orignx\"]\n",
    "    end\n",
    "    seconds_per_file = samples_per_file/N.fs[1]\n",
    "    num_files = length(files)\n",
    "    num_chans = chans[2]-chans[1]+1\n",
    "    midpoint = Int64(chans[1]+(chans[2]+1-chans[1])/2-1)\n",
    "\n",
    "    # make iterator for saving substacks\n",
    "    t = 1\n",
    "    \n",
    "    # make output matrix and dummy NodalFFTData\n",
    "    corr_mat = zeros(Int64((maxlag*fs)*2+1), Int64(num_chans*(num_chans-1)/2)) |> cu\n",
    "    global NF = rfft(N,[1])\n",
    "    \n",
    "    # open file for error handling\n",
    "    error_file = open(out_path*\"errors.txt\", \"a\")\n",
    "    \n",
    "    # iterate through each file\n",
    "    for i=1:num_files\n",
    "        \n",
    "        # exception handling\n",
    "        try\n",
    "        \n",
    "            # read the file\n",
    "            N = read_nodal(\"segy\", files[i])[chans[1]:chans[end]]\n",
    "\n",
    "                # check that file is correct length\n",
    "                if N.info[\"orignx\"] == samples_per_file && isempty(N.data) == false\n",
    "                    # preprocess\n",
    "                    resample!(N,fs)\n",
    "                    detrend!(N)\n",
    "                    taper!(N)\n",
    "                    bandpass!(N,freqmin,freqmax,zerophase=true)\n",
    "\n",
    "                    # send to GPU\n",
    "                    N.data = N.data |> cu\n",
    "\n",
    "                    # apply fk filter to each leg of the cable\n",
    "                    split = midpoint-chans[1]+1\n",
    "                    N_leg_1 = N[1:split]\n",
    "                    N_leg_2 = N[split+1:end]\n",
    "                    NF_leg_1 = rfft(N_leg_1,[1,2])\n",
    "                    NF_leg_2 = rfft(N_leg_2,[1,2])\n",
    "                    fk!(NF_leg_1,cmin,cmax,sgn)\n",
    "                    fk!(NF_leg_2,cmin,cmax,sgn)\n",
    "                    N_leg_1 = irfft(NF_leg_1,[1,2])\n",
    "                    N_leg_2 = irfft(NF_leg_2,[1,2])\n",
    "                    N = merge_channels(N_leg_1,N_leg_2,2)\n",
    "\n",
    "                    # spectral whitening- probably can group fk and whitening to remove one fft\n",
    "                    # need to get updated whitening code up to snuff\n",
    "                    NF = rfft(N,[1])\n",
    "                    whiten!(NF,freqmin,freqmax)\n",
    "                    N = irfft(NF,[1])\n",
    "\n",
    "                    # one bit normalization\n",
    "                    N.data .= sign.(N.data)\n",
    "\n",
    "                    # slice\n",
    "                    sliced_data = slice(N,10)\n",
    "                    NP = NodalProcessedData(N.n,size(sliced_data)[1],N.ox,N.oy,N.oz,N.info,N.id,N.name,\n",
    "                               N.loc,fs*ones(N.n),N.gain,Float64(freqmin),Float64(freqmax),cc_len,\"1bit\",\n",
    "                               N.resp,N.units,N.src,N.misc,N.notes,N.t,sliced_data)\n",
    "\n",
    "                    # cross correlate- CHECKED\n",
    "                    NF = rfft(NP,[1])\n",
    "                    corr = correlate(NF,Int64(maxlag*NF.fs[1]))\n",
    "                    corr_mat = corr_mat + sum(corr,dims=3)\n",
    "                end\n",
    "            \n",
    "        # exception handling\n",
    "        catch error\n",
    "            bt = backtrace()\n",
    "            msg = sprint(showerror, error, bt)\n",
    "            error_string = \"\\nError on file: \"*files[i]*\"\\n\"*msg*\"\\n\"\n",
    "            write(error_file,error_string)\n",
    "        end\n",
    "        \n",
    "        # count time steps and save output\n",
    "        if i > 1\n",
    "            datetime = datetime + Second(seconds_per_file)\n",
    "        end       \n",
    "        if datetime <= output_times[t] && datetime+Second(seconds_per_file) > output_times[t]\n",
    "            t = t + 1\n",
    "            corr_mat = real(reshape(Array(corr_mat),size(corr_mat,1),size(corr_mat,2)))\n",
    "            NC = NodalCorrData(NF.n,NF.ox,NF.oy,NF.oz,NF.info,NF.id,NF.name,NF.loc,NF.fs,\n",
    "                               NF.gain,NF.freqmin,NF.freqmax,cc_len,maxlag,\"1bit\",true,NF.resp,NF.units,\n",
    "                               NF.src,NF.misc,NF.notes,NF.t,corr_mat)\n",
    "            fname = string(out_path,\"correlations_\",datetime,\".jld2\")\n",
    "            JLD2.save(fname,Dict(\"NodalCorrData\"=>NC))\n",
    "\n",
    "            # clear output matrix\n",
    "            corr_mat = zeros(Int64((maxlag*fs)*2+1), Int64(num_chans*(num_chans-1)/2)) |> cu\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    close(error_file)\n",
    "    return\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b48ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pos\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all 1khz and resampled Greenland files\n",
    "path_1khz = \"/1-fnp/petasaur/p-wd03/greenland/Store Glacier DAS data/\"\n",
    "path_resampled = \"/1-fnp/pnwstore1/p-wd05/greenland/resampled/\"\n",
    "files_1khz = glob(\"1kHz/*\",path_1khz)\n",
    "files_resampled = glob(\"*\",path_resampled)\n",
    "files = cat(files_1khz,files_resampled,dims=1)\n",
    "N = read_nodal(\"segy\", files[2])\n",
    "\n",
    "# choose channels\n",
    "chan_start = 331\n",
    "chan_end = Int64(N.n-chan_start+1)\n",
    "chans = [chan_start,chan_end]\n",
    "\n",
    "# set filter band\n",
    "freqmin,freqmax = 1,20\n",
    "fs = freqmax*2+1\n",
    "\n",
    "# set time normalization\n",
    "time_norm = \"1bit\"\n",
    "\n",
    "# set windowing parameters\n",
    "cc_len = 10\n",
    "maxlag = 1\n",
    "\n",
    "# choose fk filter bounds\n",
    "cmin,cmax = 1000,4000\n",
    "sgn = \"pos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8645e8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2358"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chan_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e734046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set substack timing and output path\n",
    "substack_time = Hour(1)\n",
    "Ns,Nf = read_nodal(\"segy\", files_1khz[2]), read_nodal(\"segy\", files_1khz[end])\n",
    "start_datetime,end_datetime = get_datetime(Ns),get_datetime(Nf)\n",
    "output_times = start_datetime+substack_time:substack_time:end_datetime\n",
    "out_path = string(\"/fd1/solinger/correlations/1khz/fk_\",cmin,\"_\",cmax,\"/all/fk_\",sgn,\"/\")\n",
    "\n",
    "# correlate 1khz files\n",
    "workflow(files[2:end],cc_len,maxlag,freqmin,freqmax,fs,\n",
    "              cmin,cmax,sgn,time_norm,chans,output_times,out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1a1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized workflow (to use, paste in inner loop of workflow function)\n",
    "\n",
    "# time-domain preprocessing\n",
    "NP = preprocess(N,freqmin,freqmax,fs,cc_len,time_norm)\n",
    "\n",
    "# fk filter\n",
    "NF = rfft(NP,[1,2])\n",
    "fk!(NF,cmin,cmax,sgn)\n",
    "NF = irfft(NF,[2])\n",
    "\n",
    "# spectral whitening- probably can group fk and whitening to remove one fft\n",
    "# need to get updated whitening code up to snuff\n",
    "whiten!(NF,freqmin,freqmax)\n",
    "\n",
    "# cross correlate- CHECKED\n",
    "NF.fft = NF.fft |> cu\n",
    "corr = correlate(NF,Int64(maxlag*NF.fs[1]))\n",
    "corr_mat = corr_mat + sum(corr,dims=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO \n",
    "# reconcile workflow and whitening \n",
    "#    wasteful fftw\n",
    "#    whitening on each window the concatenating is not the same as whiting on entire file\n",
    "# characterize noise spectra\n",
    "# dv/v mostly due to diurnal velocity change!\n",
    "# edge effects for narrow fk bands (when cmin increases)\n",
    "# cross cable stacking- right now, seems like we get / + \\ but do we want \\ + \\?\n",
    "# think about pre-correlation filtering- if most signal power is at 5 hz, for instance, if we correlate on\n",
    "# 1-100 Hz, could we possibly see anything meaningful at higher frequency (like 50-60 Hz, for instance)\n",
    "# make NodalCorrData object"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
