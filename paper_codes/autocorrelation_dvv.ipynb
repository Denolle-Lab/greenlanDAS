{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91d9aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_autocorr_space (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SeisNoise, SeisBase, PyPlot, CUDA, Glob, HDF5, Combinatorics, Random, Statistics, ImageFiltering, FFTW, JLD2, Dates\n",
    "import SeisNoise: NoiseData \n",
    "import SeisBase: read_nodal, NodalData, InstrumentPosition, InstrumentResponse, show_str, show_t, show_x, show_os\n",
    "import FFTW: rfft, irfft\n",
    "import DSP: hilbert\n",
    "import Images: findlocalmaxima\n",
    "import Base:show, size, summary\n",
    "import PyCall\n",
    "import SeisDvv\n",
    "import Dates\n",
    "import FiniteDifferences\n",
    "import CSV\n",
    "using NetCDF\n",
    "using DataFrames\n",
    "include(\"../correlation/functions/Types.jl\")\n",
    "include(\"../correlation/functions/Nodal.jl\")\n",
    "include(\"../correlation/functions/Misc.jl\")\n",
    "include(\"../correlation/functions/Workflow.jl\")\n",
    "include(\"../correlation/functions/Dvv.jl\")\n",
    "include(\"../correlation/functions/Plot.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf93098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\n",
    "\n",
    "Read and preprocess autocorrelations\n",
    "\n",
    "\"\n",
    "\n",
    "# frequency bands to return\n",
    "bands = [[10. 13.];]\n",
    "\n",
    "# set number of samples and correlations\n",
    "ns = 801\n",
    "ncorr = 3090\n",
    "\n",
    "# processing parameters\n",
    "cmin,cmax = 3500,4250\n",
    "\n",
    "# get files and datetimes\n",
    "files, path, datetimes = get_files_and_datetimes(cmin,cmax)\n",
    "\n",
    "# restack time\n",
    "restack_interval = 30\n",
    "\n",
    "# get autocorrs\n",
    "restack_times, all_autocorrs = collect_autocorrs(files,datetimes,restack_interval,ns,ncorr,bands)\n",
    "\n",
    "# save the autocorrelations and datetime information\n",
    "fname = string(path,\"autocorrelations_\",Int(bands[1,1]),\"-\",Int(bands[end,2]),\"Hz_\",restack_interval,\"_min_stack.jld2\")\n",
    "JLD2.save(fname,Dict(\"autocorrs\"=>all_autocorrs))\n",
    "fname = string(path,\"datetimes_\",restack_interval,\"_min_stack.jld2\")\n",
    "JLD2.save(fname,Dict(\"datetimes\"=>collect(restack_times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a212554",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\n",
    "\n",
    "Visualize the autocorrelation functions in time and space\n",
    "\n",
    "\"\n",
    "\n",
    "# choose which stacking\n",
    "restack_interval = 30\n",
    "\n",
    "# choose frequency bands\n",
    "bands = [[10. 13.];]\n",
    "\n",
    "# load p-wave autocorrelations\n",
    "path = string(\"/fd1/solinger/correlations/fk_3500_4250/no_whitening/10_min/icequakes_removed/\")\n",
    "fname = string(path,\"autocorrelations_\",Int(bands[1,1]),\"-\",Int(bands[end,2]),\"Hz_\",restack_interval,\"_min_stack.jld2\")\n",
    "p_autocorrs = JLD2.load(fname)[\"autocorrs\"]\n",
    "zero_ind = size(p_autocorrs,1)รท2+1\n",
    "pos_p_autocorrs = p_autocorrs[zero_ind:end,:,:,:]\n",
    "\n",
    "# load s-wave autocorrelations\n",
    "path = string(\"/fd1/solinger/correlations/fk_1500_2250/no_whitening/10_min/icequakes_removed/\")\n",
    "fname = string(path,\"autocorrelations_\",Int(bands[1,1]),\"-\",Int(bands[end,2]),\"Hz_\",restack_interval,\"_min_stack.jld2\")\n",
    "s_autocorrs = JLD2.load(fname)[\"autocorrs\"]\n",
    "zero_ind = size(s_autocorrs,1)รท2+1\n",
    "pos_s_autocorrs = s_autocorrs[zero_ind:end,:,:,:]\n",
    "\n",
    "# choose some time period to skip \n",
    "skip_time = [DateTime(2019,7,7,13),DateTime(2019,7,7,14)]\n",
    "start_time = DateTime(2019,7,6,10)\n",
    "\n",
    "# make the plot\n",
    "plot_autocorr_time(pos_p_autocorrs,pos_s_autocorrs,restack_interval,start_time,skip_time,515,path)\n",
    "plot_autocorr_space(pos_p_autocorrs[:,1:1030,:,:],pos_s_autocorrs[:,1:1030,:,:],restack_interval,start_time,skip_time,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d966e1a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\n",
    "\n",
    "Identify data gaps\n",
    "\n",
    "\"\n",
    "\n",
    "# choose run \n",
    "path_1khz = \"/1-fnp/petasaur/p-wd03/greenland/Store Glacier DAS data/\"\n",
    "path_resampled = \"/1-fnp/pnwstore1/p-wd05/greenland/data/resampled\"\n",
    "files_1khz = glob(\"1kHz/*\",path_1khz)\n",
    "files_resampled = glob(\"*\",path_resampled)\n",
    "files = cat(files_1khz,files_resampled,dims=1)\n",
    "\n",
    "# get datetimes of each file\n",
    "file_datetimes = []\n",
    "for i=1:size(files,1)\n",
    "    file_datetimes = vcat(file_datetimes,DateTime(split(split(files[i],\"AQ_\")[2],\".\")[1],dateformat\"yymmddHHMMSS\"))\n",
    "end\n",
    "\n",
    "# get time delta\n",
    "diff_vec = diff(file_datetimes)\n",
    "diff_vec_sec = []\n",
    "for i=1:size(diff_vec,1)\n",
    "    diff_vec_sec = vcat(diff_vec_sec,diff_vec[i].value/1000)\n",
    "end\n",
    "\n",
    "# make a crude plot\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,5))\n",
    "plt.scatter(file_datetimes[2:end],diff_vec_sec)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ebf599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Tuple{Vector{Int64}, String, Vector{Float64}, Int64, String, String}}:\n",
       " ([3500, 4250], \"pos\", [0.3, 0.8], 30, \"time_space_avg\", \"dx\")\n",
       " ([3500, 4250], \"neg\", [0.3, 0.8], 30, \"time_space_avg\", \"dx\")\n",
       " ([1500, 2250], \"pos\", [0.0, 0.3], 30, \"time_space_avg\", \"dx\")\n",
       " ([1500, 2250], \"neg\", [0.0, 0.3], 30, \"time_space_avg\", \"dx\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\n",
    "\n",
    "Set common parameters for dv/v calculation\n",
    "\n",
    "\"\n",
    "\n",
    "# choose frequency bands\n",
    "bands = [[10. 13.];]\n",
    "n_bands = size(bands,1)\n",
    "band = 1\n",
    "\n",
    "# set gain correction function\n",
    "gain_correct = \"none\"\n",
    "\n",
    "# set parameters for all dv/v methods\n",
    "method = \"stretching\"\n",
    "\n",
    "# set stretching parameters\n",
    "dvlims = [-0.2,0.2]\n",
    "ntrial = 100\n",
    "\n",
    "# choose some time period to skip \n",
    "skip_time = [DateTime(2019,7,7,13),DateTime(2019,7,7,14)]\n",
    "\n",
    "# 1. channelwise autocorrelation functions averaged over the entire time period\n",
    "# 2. channelwise autocorrelation functions averaged over the last hour\n",
    "ref_type = [\"time_space_avg\"] #\"time_avg\"\n",
    "\n",
    "# autocorrelation functions averaged over all channels and the entire time period\n",
    "# surface channel autocorrelation functions averaged over the entire time period\n",
    "\n",
    "# set parameters for all dv/v runs\n",
    "clims = [[3500,4250],[1500,2250]]\n",
    "tlims = [[0.3,0.8],[0.0,0.3]]\n",
    "restack_intervals = [30] #[60,30,10]\n",
    "sides = [\"pos\",\"neg\"]\n",
    "modes = [\"dx\"]\n",
    "parameters = collect(Iterators.product(clims,sides,tlims,restack_intervals,ref_type,modes))\n",
    "\n",
    "# filter out the unwanted combinations\n",
    "parameters = filter(e->e[1] == clims[1] && e[3] == tlims[1] || \n",
    "                    e[1] == clims[2] && e[3] == tlims[2],parameters)\n",
    "parameters = filter(e->e[6] == modes[1] && e[5] == ref_type[1] || \n",
    "                    e[6] == modes[2] && e[5] == ref_type[2],parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188506c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /fd1/solinger/correlations/fk_3500_4250/no_whitening/10_min/icequakes_removed/auto_dvdx_stretching_10-13Hz_0.3-0.8s_30_min_time_space_avg_ref_pos.jld2\n",
      "Saved /fd1/solinger/correlations/fk_3500_4250/no_whitening/10_min/icequakes_removed/auto_dvdx_stretching_10-13Hz_0.3-0.8s_30_min_time_space_avg_ref_neg.jld2\n",
      "Saved /fd1/solinger/correlations/fk_1500_2250/no_whitening/10_min/icequakes_removed/auto_dvdx_stretching_10-13Hz_0.0-0.3s_30_min_time_space_avg_ref_pos.jld2\n",
      "Saved /fd1/solinger/correlations/fk_1500_2250/no_whitening/10_min/icequakes_removed/auto_dvdx_stretching_10-13Hz_0.0-0.3s_30_min_time_space_avg_ref_neg.jld2\n"
     ]
    }
   ],
   "source": [
    "\"\n",
    "\n",
    "Compute dv/dt or dv/dx for each set of parameters \n",
    "(P wave / S wave, positive / negative lag, coda / ballistic, 60 / 10 minute stack)\n",
    "\n",
    "\"\n",
    "\n",
    "# iterate through list of parameters\n",
    "for parameter in parameters\n",
    "    \n",
    "    # get parameters\n",
    "    clim = parameter[1]\n",
    "    side = parameter[2]\n",
    "    tlim = parameter[3]\n",
    "    restack_interval = parameter[4]\n",
    "    ref_type = parameter[5]\n",
    "    mode = parameter[6]\n",
    "\n",
    "    # choose first hour to consider (exclude noisy period at start of deployment)\n",
    "    start_time = DateTime(2019,7,6,10)\n",
    "\n",
    "    # load autocorrelations\n",
    "    path = string(\"/fd1/solinger/correlations/fk_\",clim[1],\"_\",clim[2],\"/no_whitening/10_min/icequakes_removed/\")\n",
    "    fname = string(path,\"autocorrelations_\",Int(bands[1,1]),\"-\",Int(bands[end,2]),\"Hz_\",restack_interval,\"_min_stack.jld2\")\n",
    "    autocorrs = JLD2.load(fname)[\"autocorrs\"]\n",
    "\n",
    "    # get correct side\n",
    "    zero_ind = size(autocorrs,1)รท2+1\n",
    "    if side == \"pos\"\n",
    "        autocorrs = autocorrs[zero_ind:end,:,:,:]\n",
    "    elseif side == \"neg\"\n",
    "        autocorrs = autocorrs[1:zero_ind,:,:,:]\n",
    "        autocorrs = reverse(autocorrs,dims=1)\n",
    "    end\n",
    "\n",
    "    # read datetimes\n",
    "    fname = string(path,\"datetimes_\",restack_interval,\"_min_stack.jld2\")\n",
    "    datetimes = JLD2.load(fname)[\"datetimes\"]\n",
    "\n",
    "    # zero the window to skip\n",
    "    skip_ind = [findfirst(datetimes .> skip_time[1]),findfirst(datetimes .> skip_time[2])]\n",
    "    autocorrs[:,:,skip_ind[1]:skip_ind[2]] .= 0\n",
    "\n",
    "    # get index of first correlation\n",
    "    start_ind = findfirst(datetimes .> start_time)\n",
    "    autocorrs = autocorrs[:,:,start_ind:end,:]\n",
    "\n",
    "    # compute reference waveforms based on selected parameters\n",
    "    if mode == \"dt\"\n",
    "        if ref_type == \"time_avg\"\n",
    "            ref_corrs = sum(autocorrs[:,:,:,:],dims=3)\n",
    "        elseif ref_type == \"last\"\n",
    "            last_idx = findall(x -> x == 1, (autocorrs[1,1,:,1] .!= 0))[end]\n",
    "            ref_corrs = autocorrs[:,:,last_idx:last_idx,:]\n",
    "        end\n",
    "    elseif mode == \"dx\"\n",
    "        if ref_type == \"time_space_avg\"\n",
    "            time_avg_corrs = mean(autocorrs[:,:,(autocorrs[1,1,:,1] .!= 0),1],dims=3)\n",
    "            time_space_avg_corrs = mean(time_avg_corrs,dims=2)\n",
    "            ref_corrs = autocorrs[:,:,1:1,:]\n",
    "            ref_corrs .= time_space_avg_corrs\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # run stretching dvv computation\n",
    "    if mode == \"dt\"\n",
    "        dvv = compute_stretching_dvdt(autocorrs,ref_corrs,bands,tlim,dvlims,ntrial,gain_correct)\n",
    "    elseif mode == \"dx\"\n",
    "        if ref_type == \"time_space_avg\"\n",
    "            time_avg_autocorrs = mean(autocorrs[:,:,(autocorrs[1,1,:,1] .!= 0),1],dims=3)\n",
    "            dvv = compute_stretching_dvdx(time_avg_autocorrs,ref_corrs,bands,tlim,dvlims,ntrial,gain_correct)\n",
    "        elseif ref_type == \"cumulative\"\n",
    "            dvv = compute_stretching_dvdx_cumulative(autocorrs,bands,tlim,dvlims,ntrial,gain_correct)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # save results\n",
    "    fname = string(path,\"auto_dv\",mode,\"_\",method,\"_\",Int(bands[1,1]),\"-\",Int(bands[end,2]),\"Hz_\",tlim[1],\"-\",tlim[2],\"s_\",restack_interval,\"_min_\",ref_type,\"_ref_\",side,\".jld2\")\n",
    "    JLD2.save(fname,Dict(\"dvv\"=>dvv))\n",
    "\n",
    "    # give output\n",
    "    println(\"Saved \",fname)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\n",
    "\n",
    "Stack dv/v\n",
    "\n",
    "\"\n",
    "\n",
    "# choose which fk band\n",
    "cmin = 3500\n",
    "cmax = 4250\n",
    "\n",
    "# choose which time window\n",
    "t_win = [0.3,0.8]\n",
    "\n",
    "# choose which stacking\n",
    "restack_interval = 60\n",
    "\n",
    "# choose which reference type\n",
    "ref_type = \"time_avg\"\n",
    "\n",
    "# choose which band (probably 1)\n",
    "band = 1\n",
    "\n",
    "# choose space or time\n",
    "mode = \"dt\"\n",
    "\n",
    "# set path\n",
    "path = string(\"/fd1/solinger/correlations/fk_\",cmin,\"_\",cmax,\"/no_whitening/10_min/icequakes_removed/\")\n",
    "\n",
    "# load dv/v from positive autocorrelations\n",
    "fname = string(path,\"auto_dv\",mode,\"_\",method,\"_\",Int(bands[1,1]),\"-\",Int(bands[end,2]),\"Hz_\",t_win[1],\"-\",t_win[2],\"s_\",restack_interval,\"_min_\",ref_type,\"_pos.jld2\")\n",
    "auto_dvv_pos = JLD2.load(fname)[\"dvv\"]\n",
    "\n",
    "# load dv/v from negative autocorrelations\n",
    "fname = string(path,\"auto_dv\",mode,\"_\",method,\"_\",Int(bands[1,1]),\"-\",Int(bands[end,2]),\"Hz_\",t_win[1],\"-\",t_win[2],\"s_\",restack_interval,\"_min_\",ref_type,\"_neg.jld2\")\n",
    "auto_dvv_neg = JLD2.load(fname)[\"dvv\"]\n",
    "\n",
    "# stack downgoing, upgoing, and cross autocorrelations\n",
    "auto_dvv = auto_dvv_pos[1:1030,:,band] .+ auto_dvv_pos[1031:2060,:,band] .+ auto_dvv_pos[2061:3090,:,band]\n",
    "auto_dvv = auto_dvv .+ auto_dvv_neg[1:1030,:,band] .+ auto_dvv_neg[1031:2060,:,band] .+ auto_dvv_neg[2061:3090,:,band]\n",
    "auto_dvv = auto_dvv ./ 6\n",
    "\n",
    "# read stack datetime info\n",
    "fname = string(path,\"datetimes_\",restack_interval,\"_min_stack.jld2\")\n",
    "datetimes = JLD2.load(fname)[\"datetimes\"]\n",
    "\n",
    "# if mode = dx, cumulatively add \n",
    "if mode == \"dx\"\n",
    "    auto_dvv_sum = similar(auto_dvv)\n",
    "    for i=1:size(auto_dvv,1)\n",
    "        auto_dvv_sum[i,:] = sum(auto_dvv[1:i,:],dims=1)\n",
    "    end\n",
    "    auto_dvv = auto_dvv_sum\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2084abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\n",
    "\n",
    "Visualize dv/v\n",
    "\n",
    "\"\n",
    "\n",
    "# get time axis in local time\n",
    "datestring = []\n",
    "for i=1:size(datetimes,1)\n",
    "    datestring = vcat(datestring,Dates.format(datetimes[i],\"mm-dd\\nHH:MM\"))\n",
    "end\n",
    "\n",
    "# make color plot \n",
    "fig,ax = plt.subplots(1,1,figsize=(10,4))\n",
    "c1 = ax.imshow(auto_dvv[:,:,band],aspect=\"auto\",cmap=\"seismic\",vmin=-30,vmax=30)\n",
    "ax.set_ylabel(\"Depth\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "\n",
    "# handle date axis\n",
    "start_time = DateTime(2019,7,6,10)\n",
    "start_ind = findfirst(datetimes .> start_time)\n",
    "datelabels = [start_time+Hour(6*i) for i=0:9]\n",
    "datestring = []\n",
    "for i=1:size(datelabels,1)\n",
    "    datestring = vcat(datestring,Dates.format(datelabels[i],\"mm-dd\\nHH:MM\"))\n",
    "end\n",
    "\n",
    "# set xlims on all plots\n",
    "xticks = (datelabels.-datetimes[start_ind])./(datetimes[end].-datetimes[start_ind]).*size(auto_dvv,2)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(datestring)\n",
    "lim_ind = [findfirst(abs.(auto_dvv[1,:,1]) .> 0),size(auto_dvv,2)-1]\n",
    "ax.set_xlim(lim_ind)\n",
    "\n",
    "title = string(\"Autocorrrelation dv/\",mode,\" \\n(\",method,\", \",cmin,\"-\",cmax,\"m/s, \",Int(bands[band,1]),\"-\",Int(bands[band,2]),\"Hz, \",t_win[1],\"-\",t_win[2],\"s, \",restack_interval,\" min stack)\")\n",
    "ax.set_title(title)\n",
    "plt.colorbar(c1)\n",
    "plt.tight_layout()\n",
    "\n",
    "fname = string(\"dv\",mode,\"_\",method,\"_fk_\",cmin,\"_\",cmax,\"_\",Int(bands[band,1]),\"-\",Int(bands[band,2]),\"Hz_\",t_win[1],\"-\",t_win[2],\"s_\",restack_interval,\"_min_\",ref_type,\"_ref_stack.png\")\n",
    "plt.savefig(\"../figures/dvv/\"*fname,dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d54a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\n",
    "\n",
    "Make superplot with all the data\n",
    "\n",
    "\"\n",
    "\n",
    "# choose which phase\n",
    "phase = \"s\"\n",
    "\n",
    "# choose which stacking\n",
    "restack_interval = 10\n",
    "\n",
    "# select other parameters accordingly\n",
    "if phase == \"p\"\n",
    "    # choose which fk band\n",
    "    cmin = 3500\n",
    "    cmax = 4250\n",
    "\n",
    "    # choose which time window\n",
    "    t_win = [0.3,0.8]\n",
    "    \n",
    "elseif phase == \"s\"\n",
    "    # choose which fk band\n",
    "    cmin = 1500\n",
    "    cmax = 2250\n",
    "\n",
    "    # choose which time window\n",
    "    t_win = [0.0,0.3]\n",
    "end\n",
    "\n",
    "# choose which reference type\n",
    "ref_type = \"time_avg\"\n",
    "\n",
    "# choose start time\n",
    "start_time = DateTime(2019,7,6,10)\n",
    "\n",
    "# choose which band (probably 1)\n",
    "band = 1\n",
    "\n",
    "# choose space or time\n",
    "mode = \"dt\"\n",
    "\n",
    "# set path\n",
    "path = string(\"/fd1/solinger/correlations/fk_\",cmin,\"_\",cmax,\"/no_whitening/10_min/icequakes_removed/\")\n",
    "\n",
    "# load dv/v from positive autocorrelations\n",
    "fname = string(path,\"auto_dv\",mode,\"_stretching_\",Int(bands[1,1]),\"-\",Int(bands[end,2]),\"Hz_\",t_win[1],\"-\",t_win[2],\"s_\",restack_interval,\"_min_\",ref_type,\"_pos.jld2\")\n",
    "auto_dvv_pos = JLD2.load(fname)[\"dvv\"]\n",
    "\n",
    "# load dv/v from negative autocorrelations\n",
    "fname = string(path,\"auto_dv\",mode,\"_stretching_\",Int(bands[1,1]),\"-\",Int(bands[end,2]),\"Hz_\",t_win[1],\"-\",t_win[2],\"s_\",restack_interval,\"_min_\",ref_type,\"_neg.jld2\")\n",
    "auto_dvv_neg = JLD2.load(fname)[\"dvv\"]\n",
    "\n",
    "# stack downgoing, upgoing, and cross autocorrelations\n",
    "auto_dvv = auto_dvv_pos[1:1030,:,band] .+ auto_dvv_pos[1031:2060,:,band] .+ auto_dvv_pos[2061:3090,:,band]\n",
    "auto_dvv = auto_dvv .+ auto_dvv_neg[1:1030,:,band] .+ auto_dvv_neg[1031:2060,:,band] .+ auto_dvv_neg[2061:3090,:,band]\n",
    "auto_dvv = auto_dvv ./ 6\n",
    "\n",
    "# read stack datetime info\n",
    "fname = string(path,\"datetimes_\",restack_interval,\"_min_stack.jld2\")\n",
    "datetimes = JLD2.load(fname)[\"datetimes\"]\n",
    "\n",
    "# read borehole pressure\n",
    "if phase == \"p\"\n",
    "    p_file = \"../borehole_data/BH19e_pressure.csv\"\n",
    "elseif phase == \"s\"\n",
    "    p_file = \"../borehole_data/BH19c_pressure.csv\"\n",
    "end\n",
    "p_BH19 = DataFrame(CSV.File(p_file))\n",
    "format = \"yyyy-mm-dd HH:MM:SS\"\n",
    "t_BH19 =  [DateTime(p_BH19[i,1],format) for i in range(1,size(p_BH19,1))]\n",
    "\n",
    "# read ice velocity\n",
    "gnss = DataFrame(CSV.File(\"../borehole_data/R30_GNSS.csv\"))\n",
    "t_gnss = [DateTime(gnss[i,1],format) for i in range(1,size(gnss,1))]\n",
    "\n",
    "# set time offset for borehole data from later\n",
    "shift = Dates.Day(23)\n",
    "\n",
    "# detrend pressure within time period of interest\n",
    "if phase == \"p\"\n",
    "    t_p_shift = t_BH19 - shift\n",
    "    p_shift = p_BH19[:,3][(t_p_shift .< datetimes[end]) .&& (t_p_shift .> start_time)]\n",
    "    t_p_shift = t_p_shift[(t_p_shift .< datetimes[end]) .&& (t_p_shift .> start_time)]\n",
    "    detrend!(p_shift)\n",
    "elseif phase == \"s\"\n",
    "    p_shift = p_BH19[:,3][(t_BH19 .< datetimes[end]) .&& (t_BH19 .> start_time)]\n",
    "    t_p_shift = t_BH19[(t_BH19 .< datetimes[end]) .&& (t_BH19 .> start_time)]\n",
    "    detrend!(p_shift)\n",
    "end\n",
    "\n",
    "# detrend pressure within time period of interest \n",
    "t_v_shift = t_gnss - shift\n",
    "v_shift = gnss[:,6][(t_v_shift .< datetimes[end]) .&& (t_v_shift .> start_time)]\n",
    "t_v_shift = t_v_shift[(t_v_shift .< datetimes[end]) .&& (t_v_shift .> start_time)]\n",
    "detrend!(v_shift)\n",
    "\n",
    "# plot borehole pressure\n",
    "fig,ax = plt.subplots(3,1,figsize = (13,9),gridspec_kw=Dict(\"height_ratios\" => [1,3,1]))\n",
    "\n",
    "# handle some date stuff\n",
    "mdates = PyCall.pyimport((\"matplotlib.dates\"))\n",
    "date_format = mdates.DateFormatter(\"%m-%d\\n%H:%M\")\n",
    "\n",
    "# plot surface velocity\n",
    "ax[1].set_title(\"A.\",loc=\"left\",size=15)\n",
    "ax[1].plot(t_v_shift+shift,v_shift/365,label=\"Velocity\",c=\"k\",linewidth=4)\n",
    "ax[1].set_ylabel(\"Velocity perturbation \\n(m/day)\",size=15)\n",
    "ax[1].set_xlim(start_time+shift,datetimes[end]+shift)\n",
    "ax[1].grid(true) \n",
    "ax[1].xaxis.set_major_formatter(date_format)\n",
    "\n",
    "# plot borehole pressure\n",
    "if phase == \"p\"\n",
    "    ax[3].plot(t_p_shift+shift,p_shift,c=\"k\",linewidth=6)\n",
    "    ax[3].plot(t_p_shift+shift,p_shift,c=\"#95EC3A\",linewidth=4)\n",
    "    ax[3].set_xlim(start_time+shift,datetimes[end]+shift)\n",
    "elseif phase == \"s\"\n",
    "    ax[3].plot(t_p_shift,p_shift,c=\"k\",linewidth=6)\n",
    "    ax[3].plot(t_p_shift,p_shift,c=\"#E86E10\",linewidth=4)\n",
    "    ax[3].set_xlim(start_time,datetimes[end])\n",
    "end\n",
    "ax[3].set_ylabel(\"Hydraulic head \\nperturbation (m)\",size=15)\n",
    "ax[3].set_title(\"C.\",loc=\"left\",size=15)\n",
    "ax[3].grid(true)  \n",
    "ax[3].xaxis.set_major_formatter(date_format)\n",
    "\n",
    "# plot stacked dv/v\n",
    "if phase == \"p\"\n",
    "    lim = 0.75\n",
    "elseif phase == \"s\"\n",
    "    lim = 1.5\n",
    "end\n",
    "extent = [0, size(auto_dvv,2), size(auto_dvv,1)*1.017, 0]\n",
    "c1 = ax[2].imshow(auto_dvv[:,:,band],origin=\"upper\",aspect=\"auto\",cmap=\"seismic\",extent=extent,vmin=-lim,vmax=lim,interpolation=\"none\")\n",
    "ax[2].set_ylabel(\"Depth\",size=15)\n",
    "ax[2].set_title(\"B.\",loc=\"left\",size=15)\n",
    "\n",
    "# handle date axis\n",
    "datelabels = [DateTime(2019,7,6,12)+Hour(6*i) for i=0:9]\n",
    "datestring = []\n",
    "for i=1:size(datelabels,1)\n",
    "    datestring = vcat(datestring,Dates.format(datelabels[i],\"mm-dd\\nHH:MM\"))\n",
    "end\n",
    "\n",
    "# get timing info for x axis\n",
    "xticks = (datelabels.-start_time)./(datetimes[end].-start_time).*size(auto_dvv,2)\n",
    "ax[2].set_xticks(xticks)\n",
    "ax[2].set_xticklabels(datestring)\n",
    "ax[2].grid(true)  \n",
    "\n",
    "# colorbar\n",
    "box = ax[2].get_position()\n",
    "axColor = plt.axes([box.x0*1.5 + box.width*1.05, box.y0-0.025, 0.02, box.height*1.18])\n",
    "cbar = plt.colorbar(c1, cax = axColor, orientation=\"vertical\")\n",
    "cbar.set_label(\"dv/v (%)\",size=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "fname = string(\"dvv_stretching_fk_\",cmin,\"_\",cmax,\".png\")\n",
    "plt.savefig(\"../paper_figures/\"*fname,dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b1477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\n",
    "\n",
    "Design a time-dependent gain correction\n",
    "\n",
    "\"\n",
    "\n",
    "# read autocorrealtions\n",
    "fname = string(path,\"autocorrelations_\",Int(bands[1,1]),\"-\",Int(bands[end,2]),\"Hz.jld2\")\n",
    "all_autocorrs = JLD2.load(fname)[\"autocorrs\"]\n",
    "zero_ind = size(all_autocorrs,1)รท2+1\n",
    "pos_autocorrs = all_autocorrs[zero_ind:end,:,:,:]\n",
    "\n",
    "# manually fit an exponential function describing the envelope decay\n",
    "lambda = 0.04\n",
    "exp_func = exp.(-lambda*range(1,size(pos_autocorrs,1)))\n",
    "\n",
    "# make a gain correction function\n",
    "pre_trim = 40\n",
    "post_trim = pre_trim-1\n",
    "exp_func_pre = reverse(exp_func)[pre_trim:end] .- reverse(exp_func)[end]\n",
    "gain_correction = 1 .+ cat(exp_func_pre,(1 .- exp_func[1:post_trim]),dims=1)\n",
    "gain_correction = gain_correction .- gain_correction[1]\n",
    "\n",
    "# choose channel (eventually, we'll do all)\n",
    "chan_idx = 500\n",
    "\n",
    "# get average autocorrelation\n",
    "start_ind = 14\n",
    "ref_s = sum(pos_autocorrs[:,chan_idx,start_ind:end,1],dims=2)\n",
    "ref_s = ref_s./(size(pos_autocorrs,3)-start_ind+1)\n",
    "t = range(0,1,size(pos_autocorrs,1))\n",
    "\n",
    "# plot result\n",
    "fig,ax = plt.subplots(3,1,figsize=(7,10))\n",
    "ax[1].plot(t,ref_s)\n",
    "ax[1].set_title(\"Reference waveform (channel 500)\")\n",
    "ax[1].set_ylabel(\"Amplitude\")\n",
    "\n",
    "# plot the gain-corrected result\n",
    "ax[2].plot(t,gain_correction)\n",
    "ax[2].set_title(\"Gain correction function\")\n",
    "ax[2].set_ylabel(\"Gain factor\")\n",
    "ax[3].plot(t,ref_s)\n",
    "ax[3].set_ylabel(\"Amplitude\")\n",
    "ax[3].set_title(\"Gain-corrected reference waveform (channel 500)\")\n",
    "ax[3].set_xlabel(\"Time (s)\")\n",
    "plt.title(\"Gain-corrected reference waveform\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21659e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\n",
    "\n",
    "Calculate dv/v for one channel of autocorrelations\n",
    "\n",
    "\"\n",
    "\n",
    "# choose channel and frequency band \n",
    "c = 70\n",
    "j = 1\n",
    "\n",
    "# get reference waveform (gain-corrected average autocorrelation at this channel)\n",
    "ref_s = mean(pos_autocorrs[:,c,start_ind:end],dims=2)\n",
    "ref_s = gain_correction .* ref_s\n",
    "ref_s = ref_s .- mean(ref_s)\n",
    "ref_s = ref_s ./ maximum(abs.(ref_s))\n",
    "ref_s = dropdims(ref_s,dims=2)\n",
    "\n",
    "# iterate through each hour\n",
    "dvv = zeros((start_ind:size(pos_autocorrs,3)))\n",
    "for i=start_ind:size(pos_autocorrs,3)\n",
    "\n",
    "    # get gain-corrected waveform to compare with reference\n",
    "    s = pos_autocorrs[:,c,i] .* gain_correction\n",
    "    s = s .- mean(s)\n",
    "    s = s ./ maximum(abs.(s))\n",
    "    \n",
    "    # calculate dv/v with MWCS\n",
    "    dvv[i],cc,cdp,ฯต,err,allC = SeisDvv.stretching(ref_s,s,t,t_window,10.,25.,dvmin=dvmin,dvmax=dvmax,ntrial=ntrial)\n",
    "end\n",
    "\n",
    "# plot the result\n",
    "plt.plot(dvv)\n",
    "print(mean(dvv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf7970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\n",
    "\n",
    "Extract adjacent / surrounding cross correlations for dv/v stacking\n",
    "\n",
    "\"\n",
    "\n",
    "# list all correlation files\n",
    "path = string(\"/fd1/solinger/correlations/fk_\",cmin,\"_\",cmax,\"/no_whitening/\")\n",
    "files = glob(\"*0.jld2\",path)\n",
    "files = files[BitVector(1 .- contains.(files,\"error\"))]\n",
    "files = files[BitVector(1 .- contains.(files,\"autocorrelation\"))]\n",
    "\n",
    "# set number of channels on each side to include\n",
    "chan_bin_width = 5\n",
    "num_hours = size(files,1)\n",
    "\n",
    "# make output container\n",
    "stack_corrs = zeros(803,chans[2]-chans[1]+1,chan_bin_width,num_hours)\n",
    "\n",
    "# get indicies for correlations\n",
    "chan_pairs = collect(with_replacement_combinations(collect(chans[1]:chans[2]),2))\n",
    "chan_pairs = reduce(vcat,transpose.(chan_pairs))\n",
    "\n",
    "# get indices of correlation functions\n",
    "for i = 1:size(files,1)\n",
    "\n",
    "    # read and filter\n",
    "    C = JLD2.load(files[i])[\"NodalCorrData\"]\n",
    "    C_filt = deepcopy(C)\n",
    "    clean_up!(C_filt,freqmin,freqmax)\n",
    "    abs_max!(C_filt)\n",
    "\n",
    "    for c = 1:chans[2]-chans[1]+1\n",
    "        chan = chans[1]+c-1\n",
    "        for j in 1:chan_bin_width\n",
    "            corr_ind = ((chan_pairs[:,1] .== chan-j) .&& (chan_pairs[:,2] .== chan+j))\n",
    "            if sum(corr_ind) == 1\n",
    "                corr = C_filt.corr[:,corr_ind]\n",
    "                stack_corrs[:,c,j,i] = corr\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# save the correlations\n",
    "fname = string(path,\"adjacent_correlations_\",freqmin,\"-\",freqmax,\"Hz.jld2\")\n",
    "JLD2.save(fname,Dict(\"corrs\"=>stack_corrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\n",
    "\n",
    "Calculate dv/v for adjacent correlations\n",
    "\n",
    "\"\n",
    "\n",
    "\n",
    "\n",
    "# choose if computing dv/v in reference to autocorrelation stack or adjacent correlation stack\n",
    "ref = \"adj\"\n",
    "\n",
    "# make output containers\n",
    "dvv = zeros(size(pos_corrs,2),size(pos_corrs,3),size(pos_corrs,4),n_bands)\n",
    "dvv0 = zeros(size(pos_corrs,2),size(pos_corrs,3),size(pos_corrs,4),n_bands)\n",
    "\n",
    "# iterate through channel\n",
    "for c=1:size(pos_corrs,2)\n",
    "    \n",
    "    # get reference waveform (gain-corrected average autocorrelation at this channel)\n",
    "    ref_s = 0\n",
    "    if ref == \"auto\"\n",
    "        ref_s = sum(pos_autocorrs[:,c,start_ind:end],dims=2)\n",
    "        ref_s = ref_s./(size(pos_autocorrs,3)-start_ind+1)\n",
    "        ref_s = gain_correction .* ref_s\n",
    "        ref_s = ref_s .- mean(ref_s)\n",
    "        ref_s = ref_s ./ maximum(abs.(ref_s))\n",
    "    end\n",
    "    \n",
    "    # iterate through each hour\n",
    "    for i=start_ind:size(pos_corrs,4)\n",
    "        \n",
    "        # iterate through each adjacent correlation\n",
    "        for k = 1:size(pos_corrs,3)\n",
    "            \n",
    "            # get reference waveform (gain-corrected average adjacent correlation for this channel pair)\n",
    "            if ref == \"adj\"\n",
    "                ref_s = sum(pos_corrs[:,c,k,start_ind:end],dims=2)\n",
    "                ref_s = ref_s./(size(pos_autocorrs,4)-start_ind+1)\n",
    "                ref_s = gain_correction .* ref_s\n",
    "                ref_s = ref_s .- mean(ref_s)\n",
    "                ref_s = ref_s ./ maximum(abs.(ref_s))\n",
    "            end\n",
    "            \n",
    "            # get gain-corrected waveform to compare with reference\n",
    "            s = pos_corrs[:,c,k,i] .* gain_correction\n",
    "            s = s .- mean(s)\n",
    "            s = s ./ maximum(abs.(s))\n",
    "\n",
    "            # check if empty (will be first and last few)\n",
    "            if sum(s) != 0 && ~isnan(sum(s))\n",
    "\n",
    "                # iterate through each frequency band\n",
    "                for j=1:n_bands\n",
    "\n",
    "                    # calculate dv/v with MCWS\n",
    "                    if method == \"mwcs\"\n",
    "                        t_mwcs,dt_mwcs,err_mwcs,mcoh_mwcs = SeisDvv.mwcs(ref_s,s,bands[j,1],bands[j,2],fs,t[t_window[1]], win_len, win_step, 0);\n",
    "                        dvv[c,k,i,j],dvv_err_mwcs,int_mwcs,int_err_mwcs,dvv0[c,k,i+start_ind-1,j],dvv0_err_mwcs = SeisDvv.mwcs_dvv(t_mwcs,dt_mwcs,err_mwcs,mcoh_mwcs,\"static\",0.0,0.0,t[t_window[1]],t[t_window[end]]-t[t_window[1]],\"right\");\n",
    "                    elseif method == \"stretching\"\n",
    "                        dvv[c,k,i,j],cc_ts,cdp_Ts,eps_ts,err_ts,allC_ts = SeisDvv.stretching(ref_s,s,t,t_window,bands[j,1],bands[j,2],dvmin=dvmin,dvmax=dvmax,ntrial=ntrial);\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# save results\n",
    "fname = string(path,\"adjacent_dvv_\",method,\"_ref_\",ref,\"_\",freqmin,\"-\",freqmax,\"Hz.jld2\")\n",
    "if method == \"mwcs\"\n",
    "    JLD2.save(fname,Dict(\"dvv\"=>dvv,\"dvv0\"=>dvv0))\n",
    "elseif method == \"stretching\"\n",
    "    JLD2.save(fname,Dict(\"dvv\"=>dvv))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86467d5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\n",
    "\n",
    "Visualize dv/v with enclosing correlations\n",
    "\n",
    "\"\n",
    "\n",
    "# load dv/v from autocorrelation\n",
    "path = string(\"/fd1/solinger/correlations/fk_\",cmin,\"_\",cmax,\"/no_whitening/\")\n",
    "fname = string(path,\"auto_dvv_\",method,\"_\",freqmin,\"-\",freqmax,\"Hz.jld2\")\n",
    "auto_dvv = JLD2.load(fname)[\"dvv\"]\n",
    "\n",
    "# load dv/v from adjacent cross-correlations\n",
    "path = string(\"/fd1/solinger/correlations/fk_\",cmin,\"_\",cmax,\"/no_whitening/\")\n",
    "fname = string(path,\"adjacent_dvv_\",method,\"_ref_adj_\",freqmin,\"-\",freqmax,\"Hz.jld2\")\n",
    "corr_dvv = JLD2.load(fname)[\"dvv\"]\n",
    "\n",
    "# choose what we're plotting\n",
    "chan = 300\n",
    "band = 1\n",
    "n_corr = 5\n",
    "weight = \"proportional\"\n",
    "\n",
    "# stack dv/v for adjacent correlations and autocorrelation\n",
    "stacked_corr_dvv = dropdims(sum(corr_dvv[:,1:n_corr,:,:],dims=2),dims=2)\n",
    "if weight == \"equal\"\n",
    "    stacked_dvv = (stacked_corr_dvv+auto_dvv)./(n_adj+1)\n",
    "elseif weight==\"proportional\"\n",
    "    stacked_dvv = (stacked_corr_dvv./n_corr+auto_dvv)./2\n",
    "end\n",
    "\n",
    "# plot dv/v from autocorrelation and adjancent cross correlations (ref auto) for a particular channel\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "title = string(\"dv/v stacking for channel at \",chan,\"m depth from \",bands[band,1],\"-\",bands[band,2],\" Hz\")\n",
    "plt.suptitle(title,fontsize=15)\n",
    "ax.plot(auto_dvv[chan,:,band],c=\"r\",alpha=0.5,label=\"Autocorr dv/v\")\n",
    "ax.plot(corr_dvv[chan,1,:,band],c=\"k\",alpha=0.1,label=\"Xcorr dv/v\")\n",
    "ax.plot(corr_dvv[chan,2,:,band],c=\"k\",alpha=0.1)\n",
    "ax.plot(corr_dvv[chan,3,:,band],c=\"k\",alpha=0.1)\n",
    "ax.plot(corr_dvv[chan,4,:,band],c=\"k\",alpha=0.1)\n",
    "ax.plot(corr_dvv[chan,5,:,band],c=\"k\",alpha=0.1)\n",
    "ax.plot(stacked_dvv[chan,:,band],c=\"k\",label=\"Stacked dv/v\")\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_ylabel(\"dv/v\")\n",
    "ax.set_title(\"Stacked dv/v of autocorrelation and enclosing cross correlations\")\n",
    "plt.show()\n",
    "\n",
    "# make color plot \n",
    "fig,ax = plt.subplots(3,1,figsize=(10,12))\n",
    "c1 = ax[1].imshow(auto_dvv[:,:,band],aspect=\"auto\",cmap=\"seismic\",vmin=-10,vmax=10)\n",
    "ax[1].set_ylabel(\"Depth\")\n",
    "ax[1].set_title(\"Autocorrrelation dv/v\")\n",
    "plt.colorbar(c1,ax=ax[1])\n",
    "\n",
    "c2 = ax[2].imshow(stacked_corr_dvv[:,:,band]/n_corr,aspect=\"auto\",\n",
    "             cmap=\"seismic\",vmin=-20,vmax=20)\n",
    "ax[2].set_ylabel(\"Depth\")\n",
    "ax[2].set_title(\"Stacked dv/v of \"*string(n_corr)*\" enclosing cross correlations\")\n",
    "plt.colorbar(c2,ax=ax[2])\n",
    "\n",
    "c3 = ax[3].imshow(stacked_dvv[:,:,band],aspect=\"auto\",cmap=\"seismic\",vmin=-20,vmax=20)\n",
    "ax[3].set_ylabel(\"Depth\")\n",
    "ax[3].set_title(\"Stacked dv/v of autocorrelation and \"*string(n_corr)*\" enclosing cross correlations\")\n",
    "plt.colorbar(c3,ax=ax[3])\n",
    "title = string(\"Various dv/v configurations (\",bands[band,1],\"-\",bands[band,2],\" Hz)\\n\")\n",
    "plt.suptitle(title,fontsize=15)\n",
    "plt.tight_layout()\n",
    "fname = string(\"dvv_\",method,\"_\",bands[band,1],\"-\",bands[band,2],\"Hz_\",weight,\"_weight.png\")\n",
    "#plt.savefig(\"../figures/dvv/\"*fname,dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8654e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\n",
    "\n",
    "OLD Calculate dv/v for autocorrelations\n",
    "\n",
    "\"\n",
    "t_window = findall(t->t<=t_lims[2] && t>=t_lims[1], t);\n",
    "\n",
    "# make output containers\n",
    "dvv = zeros(size(autocorrs,2),size(autocorrs,3),n_bands)\n",
    "dvv0 = zeros(size(autocorrs,2),size(autocorrs,3),n_bands)\n",
    "\n",
    "# get number of empty stacks\n",
    "num_empty = sum(autocorrs[1,1,:,1] .== 0)\n",
    "\n",
    "# iterate through channel\n",
    "for c=1:size(autocorrs,2)\n",
    "    \n",
    "    # iterate through each frequency band\n",
    "    for j=1:n_bands\n",
    "            \n",
    "        # get reference waveform (gain-corrected average autocorrelation at this channel)\n",
    "        ref_s = sum(autocorrs[:,c,start_ind:end,j],dims=2)/(size(autocorrs,3)-start_ind+1-num_empty)\n",
    "        if gain_correct == true\n",
    "            ref_s = gain_correction .* ref_s\n",
    "        end\n",
    "        ref_s = ref_s .- mean(ref_s)\n",
    "        ref_s = ref_s ./ maximum(abs.(ref_s))\n",
    "        \n",
    "        # iterate through each hour\n",
    "        for i=start_ind:size(autocorrs,3)\n",
    "            \n",
    "            # check if empty\n",
    "            if sum(autocorrs[:,c,i,j]) != 0\n",
    "\n",
    "                # get gain-corrected waveform to compare with reference\n",
    "                s = autocorrs[:,c,i,j]\n",
    "                if gain_correct == true\n",
    "                    s = s.* gain_correction\n",
    "                end\n",
    "                s = s .- mean(s)\n",
    "                s = s ./ maximum(abs.(s))\n",
    "                print(s[t_window])\n",
    "                # calculate dv/v with MWCS\n",
    "                if method == \"mwcs\"\n",
    "                    t_mwcs,dt_mwcs,err_mwcs,mcoh_mwcs = SeisDvv.mwcs(ref_s,s,bands[j,1],bands[j,2],fs,t[t_window[1]], win_len, win_step, 0);\n",
    "                    dvv[c,i,j],dvv_err_mwcs,int_mwcs,int_err_mwcs,dvv0[c,i+start_ind-1,j],dvv0_err_mwcs = SeisDvv.mwcs_dvv(t_mwcs,dt_mwcs,err_mwcs,mcoh_mwcs,\"static\",0.0,0.0,t[t_window[1]],t[t_window[end]]-t[t_window[1]],\"right\");\n",
    "                elseif method == \"stretching\"\n",
    "                    dvv[c,i,j],cc_ts,cdp_Ts,eps_ts,err_ts,allC_ts = SeisDvv.stretching(ref_s,s,t,t_window,bands[j,1],bands[j,2],dvmin=dvmin,dvmax=dvmax,ntrial=ntrial);\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# save results\n",
    "fname = string(path,\"auto_dvv_\",method,\"_\",Int(bands[1,1]),\"-\",Int(bands[end,2]),\"Hz_\",t_win[1],\"-\",t_win[2],\"s_\",restack,\"_min_\",side,\".jld2\")\n",
    "if method == \"mwcs\"\n",
    "    JLD2.save(fname,Dict(\"dvv\"=>dvv,\"dvv0\"=>dvv0))\n",
    "elseif method == \"stretching\"\n",
    "    JLD2.save(fname,Dict(\"dvv\"=>dvv))\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fcdd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
